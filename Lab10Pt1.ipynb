{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_691264901b80819190cbf0e56690d39d\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-3PbL26Rbs32pogXwnwCrZw\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text.json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-3PbL26Rbs32pogXwnwCrZw\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e96e622-9b8c-47d5-9a4a-3c3e6315b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of the latest updates in 2023, several key developments have emerged in the field of generative AI:\n",
       "\n",
       "1. **Advanced Multimodal Models**: New models can handle and integrate multiple types of data such as text, images, audio, and video, increasing their versatility and application range.\n",
       "\n",
       "2. **Improved Scaling and Efficiency**: Efforts to make large language models more efficient and environmentally friendly are underway, focusing on reducing computational costs and energy consumption.\n",
       "\n",
       "3. **Fine-Tuning and Customization**: Increased emphasis on fine-tuning models for specific applications or industries, allowing for more targeted and effective outputs.\n",
       "\n",
       "4. **Ethical AI and Bias Reduction**: Ongoing work to address ethical concerns, bias mitigation, and the development of guidelines to ensure responsible AI deployment.\n",
       "\n",
       "5. **Real-Time and Interactive Applications**: Enhanced capabilities for real-time interaction in applications like virtual assistants, chatbots, and collaborative creative tools.\n",
       "\n",
       "6. **Creative and Artistic Collaborations**: Generative AI is inspiring new forms of art and content creation, being used in music, visual arts, and storytelling.\n",
       "\n",
       "7. **Increased Accessibility**: More user-friendly platforms and tools are being developed to make generative AI accessible to non-experts, expanding its use across various sectors.\n",
       "\n",
       "These trends highlight the rapid advancement and integration of generative AI into everyday applications and industries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in generative AI include several exciting advancements:\n",
       "\n",
       "1. **OpenAI's Sora2**: This tool allows for the creation of cinematic videos from a simple prompt, incorporating audio, physics, and cameos, which is a game-changer for creators.\n",
       "\n",
       "2. **Generative AI in Business**: Companies are using generative AI to innovate across various sectors, from content creation to strategic planning.\n",
       "\n",
       "3. **AI in Supply Chain**: Atos has developed an AI-powered Supply Chain Disruption Analysis using generative AI to assess risks and boost resilience.\n",
       "\n",
       "4. **Enterprise Applications**: IBM's Watsonx is bringing generative AI to enterprises, allowing teams to build custom large language models to enhance customer engagement and streamline processes.\n",
       "\n",
       "5. **Creative Industries**: Generative AI is transforming creative industries by enabling new forms of content creation and design.\n",
       "\n",
       "These developments highlight the diverse applications and transformative potential of generative AI across different fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a structured and in‚Äëdepth overview of the **latest developments in generative AI** as of Monday, November 10, 2025. This summary spans key model advancements, new tools and infrastructure, strategic industry moves, and emerging research directions.\n",
       "\n",
       "---\n",
       "\n",
       "##  Generative AI Model Milestones\n",
       "\n",
       "- **OpenAI‚Äôs GPT‚Äë5 (released August 7, 2025)**  \n",
       "  GPT‚Äë5 represents a major leap in multimodal generative AI, integrating reasoning, fast and high-throughput models, and autonomous tool use under one system. The architecture includes multiple specialized variants‚Äî‚Äúmain‚Äù, ‚Äúthinking‚Äù, and ‚Äúnano‚Äù for optimized performance, with dynamic routing to select the appropriate model per task. Access is available via ChatGPT, Microsoft Copilot, and the OpenAI API.  \n",
       "  ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- **Google‚Äôs Gemini 2.5 Pro and Nano Banana**  \n",
       "  Google upgraded its flagship model with the release of Gemini 2.5 Pro, offering enhanced reasoning, coding, and multimodal capabilities, including audio output and a ‚ÄúDeep Think‚Äù mode for complex tasks.  \n",
       "  ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai))  \n",
       "  In August 2025, Google DeepMind launched ‚ÄúNano Banana‚Äù (officially Gemini 2.5¬†Flash Image), a viral text-to-image generation tool capable of photorealistic ‚Äú3D figurine‚Äù edits, with features like subject consistency, multi-image fusion, context awareness, and invisible SynthID watermarking.  \n",
       "  ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))\n",
       "\n",
       "- **Runway‚Äôs Gen‚Äë4 for Text-to-Video Creation**  \n",
       "  Released March 31, 2025, Gen‚Äë4 is a text-to-video model that produces short (5‚Äì10 seconds), 720p, 24 fps video clips with consistent character behavior and simulated camera motion using diffusion-based architectures.  \n",
       "  ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gen-4_%28AI_image_and_video_model%29?utm_source=openai))\n",
       "\n",
       "- **OpenAI‚Äôs Sora and Other Emerging Capabilities**  \n",
       "  While not yet widely publicized, OpenAI‚Äôs Sora‚Äîan AI capable of generating videos from text prompts‚Äîreceived positive early buzz for its realism and speed, although full confirmation of its release status remains unclear.  \n",
       "  ([nexthorizon.space](https://www.nexthorizon.space/2025/04/generative-ai-breakthroughs-2025-whats-new-and-what-truly-impressed.html?utm_source=openai))\n",
       "\n",
       "- **Open‚ÄëSource Model Advances: Alibaba Qwen and Meta Llama 4**  \n",
       "  Alibaba has significantly expanded its Qwen model family‚Äîincluding the multimodal Qwen2.5‚ÄëOmni and large-scale Qwen3 series‚Äîsome components released under Apache 2.0 license, with ‚Äúthinking‚Äù capabilities enabled for Qwen3‚ÄëMax in early November‚ÄØ2025.  \n",
       "  ([en.wikipedia.org](https://en.wikipedia.org/wiki/Qwen?utm_source=openai))  \n",
       "  Meta introduced its Llama‚ÄØ4 family in April‚ÄØ2025, featuring mixture-of-experts (MoE) models like Scout (109B parameters) and Maverick (402B parameters), supporting massive 10M-token context windows and multimodal input, enabling advanced scalability with efficiency.  \n",
       "  ([ts2.tech](https://ts2.tech/en/generative-ai-revolution-2025-breakthroughs-industry-disruption-and-predictions-through-2035/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Hardware, Infrastructure, and Ecosystem Trends\n",
       "\n",
       "- **Qualcomm‚Äôs AI200 and AI250 Accelerators (arriving 2026‚Äì2027)**  \n",
       "  Qualcomm announced the AI200 and AI250 rack-scale inference accelerators, featuring advanced Hexagon NPUs with micro-tile inferencing, 64-bit addressing, model encryption, and massive LPDDR memory. These target large-scale generative AI workloads with improved efficiency and integration into major AI frameworks.  \n",
       "  ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai))\n",
       "\n",
       "- **Nvidia‚Äôs Next-Generation AI Chips**  \n",
       "  At GTC 2025, Nvidia revealed its forthcoming Blackwell Ultra (second half of 2025), Vera‚ÄØRubin (late 2026), and Rubin Ultra (2027) architectures‚Äîaimed at powering reasoning- and agent-capable generative AI workloads. Nvidia also unveiled its Isaac GR00T N1 humanoid robot model, the Cosmos synthetic data platform for robotics, and the Newton physics engine (developed with Google DeepMind and Disney Research) for robotics simulation.  \n",
       "  ([apnews.com](https://apnews.com/article/457e9260aa2a34c1bbcc07c98b7a0555?utm_source=openai))\n",
       "\n",
       "- **OpenAI‚ÄìOracle Stargate Data Center Expansion**  \n",
       "  OpenAI, in partnership with Oracle (and supported by SoftBank), is expanding its Stargate AI infrastructure initiative with an additional 4.5 GW of computing capacity‚Äîbringing total deployment above 5 GW across more than 2 million chips. The broader plan targets up to 10 GW and a potential $500 billion investment.  \n",
       "  ([reuters.com](https://www.reuters.com/business/openai-oracle-deepen-ai-data-center-push-with-45-gigawatt-stargate-expansion-2025-07-22/?utm_source=openai))\n",
       "\n",
       "- **AWS GAIA Accelerator Program**  \n",
       "  Amazon Web Services has launched its third Generative AI Accelerator (GAIA) cohort of 40 startups worldwide, offering eight weeks of mentoring and tools to help scale foundational model and infrastructure innovation.  \n",
       "  ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/aws-selects-40-startups-for-2025-generative-ai-accelerator-program/articleshow/124377434.cms?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Business, Media & Creative Applications\n",
       "\n",
       "- **TIME AI Agent‚ÄîA New Frontier in Interactive Journalism**  \n",
       "  On November 10, 2025 (today), TIME launched the TIME AI Agent, a unified generative AI platform developed with Scale AI. It enables personalized summaries, audio reports, translations, and interactive content powered by robust moderation and data governance‚Äîmarking a shift toward truly interactive AI-driven journalism.  \n",
       "  ([time.com](https://time.com/7332572/the-story-behind-the-time-ai-agent/?utm_source=openai))\n",
       "\n",
       "- **AI‚ÄëDriven Filmmaking with Darren Aronofsky‚Äôs Primordial Soup**  \n",
       "  Filmmaker Darren Aronofsky‚Äôs creative studio‚ÄîPrimordial‚ÄØSoup‚Äîpartnered with Google DeepMind to merge live-action with generative visuals in the short film *ANCESTRA*, slated for debut at the 2025 Tribeca Festival.  \n",
       "  ([en.wikipedia.org](https://en.wikipedia.org/wiki/Primordial_Soup_%28studio%29?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Research Frontiers and Emerging Paradigms\n",
       "\n",
       "- **Semantically-Centric Frameworks for Multimedia AI**  \n",
       "  A new research framework proposes integrating semantic information theory‚Äîintroducing metrics like semantic entropy and mutual information‚Äîto improve the fidelity and efficiency of generative models in multimedia contexts.  \n",
       "  ([arxiv.org](https://arxiv.org/abs/2508.17163?utm_source=openai))\n",
       "\n",
       "- **Evolutionary Computation as Natural Generative AI (NatGenAI)**  \n",
       "  A recent study repositions evolutionary computation within the generative AI paradigm, arguing it enables more creative, out-of-distribution generation via exploratory search, disrupting conventional gradient-based approaches.  \n",
       "  ([arxiv.org](https://arxiv.org/abs/2510.08590?utm_source=openai))\n",
       "\n",
       "- **Quantum Generative Models Achieving Beyond-Classical Advantage**  \n",
       "  Researchers showcased quantum generative models on a 68-qubit superconducting processor that can learn and sample distributions inaccessible to classical computing‚Äîdemonstrating both training and generation in beyond-classical regimes with no barren plateaus.  \n",
       "  ([arxiv.org](https://arxiv.org/abs/2509.09033?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## Summary Table of Key Trends (Nov 2025)\n",
       "\n",
       "- Model Innovation: GPT‚Äë5, Gemini‚ÄØ2.5‚ÄØPro, Nano‚ÄØBanana, Qwen3, Llama‚ÄØ4, Runway Gen‚Äë4  \n",
       "- Hardware & Infrastructure: Qualcomm accelerators, Nvidia Blackwell/Rubin chips, OpenAI‚ÄëOracle Stargate, AWS GAIA  \n",
       "- Creative & Media: TIME AI Agent, AI‚Äëenhanced film production  \n",
       "- Research & Theory: Semantic multimedia frameworks, NatGenAI, quantum generative advantage  \n",
       "\n",
       "---\n",
       "\n",
       "### Final Takeaways\n",
       "\n",
       "1. **Diversification of Generative AI**: We see parallel innovation across text (GPT‚Äë5), image (Nano‚ÄØBanana), video (Gen‚Äë4, Sora), and even robotics/world modeling (Nvidia, DeepMind).  \n",
       "2. **Speed and Reasoning Take Center Stage**: Models increasingly blend fast throughput with deep reasoning (GPT‚Äë5, Gemini‚ÄØ2.5‚ÄØPro, Qwen3).  \n",
       "3. **Infrastructure Scaling**: Massive computation investments‚Äîfrom data centers to specialized chips‚Äîare accelerating AI's scalability and efficiency.  \n",
       "4. **Creative Synergy**: Media brands like TIME and filmmakers like Aronofsky are embedding generative AI in storytelling and journalism.  \n",
       "5. **New Paradigms Emerge**: Evolutionary and quantum generative models, along with semantic frameworks, are pushing the boundaries of what \"generation\" means in AI.\n",
       "\n",
       "---\n",
       "\n",
       "Let me know if you'd like to dive deeper into any specific topic‚Äîmodel architecture, hardware ecosystems, creative use cases, or theoretical advances‚Äîand I can provide more detailed insights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a structured and in‚Äëdepth overview of the **latest developments in generative AI** as of Mon"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some of the **most recent and diverse news highlights** related to **generative AI**, curated from today‚Äôs publications (Monday, November 10, 2025). I‚Äôve organized the updates by theme and included at least two citations per point for accuracy and depth.\n",
       "\n",
       "---\n",
       "\n",
       "Generative AI in Action  \n",
       "‚Ä¢ **Physical AI and Vision-Language-Action (VLA) Systems**  \n",
       "  A new era is dawning where AI merges cognition with movement. Vision-language-action (VLA) systems now allow robots to interpret natural language instructions, understand their environments, and execute tasks autonomously‚Äîsignaling a major leap in embodied generative AI capabilities. ([telecomreview.com](https://telecomreview.com/articles/reports-and-coverage/27220-ai-steps-into-the-real-world-analyzing-the-rise-of-physical-ai/?utm_source=openai))  \n",
       "\n",
       "‚Ä¢ **Generative AI as a Business Risk**  \n",
       "  As businesses increasingly adopt generative technologies‚Äîfrom customer service to product development‚Äîthey face growing security threats. Experts warn that these powerful AI tools may expose organizations to unprecedented vulnerabilities if not properly managed. ([webpronews.com](https://www.webpronews.com/genais-hidden-perils-fortifying-business-defenses-in-2025/?utm_source=openai))  \n",
       "\n",
       "Infrastructure & Ecosystem  \n",
       "‚Ä¢ **Google Cloud Introduces Ironwood TPUs and Arm-Based Axion VMs**  \n",
       "  Google Cloud today launched its 7th-generation Ironwood TPUs, offering up to a 10√ó performance gain over TPU v5p and 4√ó better performance per chip than TPU v6e. Paired with new cost-efficient Arm-based Axion VMs‚Äîlike the N4A instance that delivers twice the price-performance of x86‚Äîthe offerings slash latency and serving costs, reshaping how AI workloads are scaled and deployed. ([quantumzeitgeist.com](https://quantumzeitgeist.com/google-cloud-ai-inference/?utm_source=openai))  \n",
       "\n",
       "Market & Industry Trends  \n",
       "‚Ä¢ **India‚Äôs Generative AI Market Set for Explosive Growth**  \n",
       "  A new report by IMARC Group reveals that India‚Äôs generative AI market grew to USD 1.30 billion in 2024 and is expected to soar to USD 5.40 billion by 2033. A 15.2% CAGR is projected through 2025‚Äì2033, driven by adoption in media, advertising, healthcare, and personalized content creation. ([openpr.com](https://www.openpr.com/news/4261720/india-generative-ai-market-size-share-trends-growth-report?utm_source=openai))  \n",
       "\n",
       "‚Ä¢ **Surge in Semiconductor Investment: The ‚ÄúSilicon Supercycle‚Äù**  \n",
       "  The booming demand for high-performance computing to power AI is fueling a dramatic upswing in semiconductor investments. Market sentiment is optimistic, and analysts suggest the industry may be on track toward a trillion-dollar valuation by decade‚Äôs end. ([markets.financialcontent.com](https://markets.financialcontent.com/wral/article/tokenring-2025-11-10-the-ai-gold-rush-semiconductor-investments-soar-amidst-global-tech-transformation?utm_source=openai))  \n",
       "  However, this rapid growth also brings volatility: valuations are rising, but risks are increasingly inherent in the AI-driven chip market. ([markets.financialcontent.com](https://markets.financialcontent.com/wral/article/tokenring-2025-11-10-semiconductor-stocks-navigate-ai-boom-a-volatile-ascent-amidst-trillion-dollar-dreams?utm_source=openai))  \n",
       "\n",
       "Global Engagement & Policy  \n",
       "‚Ä¢ **GBA AI and Robotics Summit Launches in Hong Kong**  \n",
       "  The ‚ÄúGBA International Artificial Intelligence and Robotics Summit 2025,‚Äù hosted by the Hong Kong Productivity Council, officially opened on November 10. Under the theme ‚ÄúEmpowering Resilient Industries through Embodied AI,‚Äù the summit convenes experts from across Hong Kong, Mainland China, and several global partners to explore industrial-scale adoption of embodied AI. ([laotiantimes.com](https://laotiantimes.com/2025/11/10/gba-international-artificial-intelligence-and-robotics-summit-2025-opens-grandly-ai-and-robotics-fest-launches-alongside-hkpc-drives-ai-for-all-and-embodied-ai-adoption-to-propel-hong-kong-into-a-ne/?utm_source=openai))  \n",
       "\n",
       "---\n",
       "\n",
       "Overall, these developments showcase a multifaceted trajectory in generative AI:\n",
       "\n",
       "- From **robotic embodiment** and **AI security concerns**\n",
       "- To **hardware breakthroughs** through custom accelerators like Ironwood and Axion\n",
       "- To **market expansion** in countries such as India\n",
       "- To **investment surges** underpinning a booming semiconductor ecosystem\n",
       "- And **international policy and collaboration**, notably in Hong Kong\n",
       "\n",
       "Let me know if you'd like to explore any of these topics further‚Äîsuch as technical specifications of Ironwood TPUs, details of VLA systems, or breakdowns of market forecasts in India."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive and up-to-date overview of the **latest developments in generative AI** as of November 10, 2025. This analysis draws on recent news, model releases, market trends, and emerging applications.\n",
       "\n",
       "---\n",
       "\n",
       "##  Major Model Releases and Innovations\n",
       "\n",
       "- **OpenAI GPT‚Äë5**  \n",
       "  Released on **August 7, 2025**, GPT‚Äë5 is a multimodal foundation model that integrates reasoning and non-reasoning capabilities under a unified interface. It is accessible via ChatGPT, Microsoft Copilot, and the OpenAI API, and represents a significant leap in performance across benchmarks. ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- **OpenAI o4‚Äëmini**  \n",
       "  Launched on **April 16, 2025**, this lightweight multimodal model supports both text and image inputs, including whiteboard sketch analysis and chain-of-thought reasoning. A higher-accuracy variant, o4‚Äëmini‚Äëhigh, is available to paid-tier users. ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai))\n",
       "\n",
       "- **OpenAI GPT‚Äë4.1**  \n",
       "  Released on **April 14, 2025**, GPT‚Äë4.1 (along with mini and nano variants) offers improved coding capabilities and is available to ChatGPT Plus and Pro subscribers. ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-4.1?utm_source=openai))\n",
       "\n",
       "- **Google DeepMind‚Äôs Gemini 2.5 Family**  \n",
       "  Google‚Äôs Gemini 2.5 Pro and Flash models, featuring enhanced reasoning, coding, and ‚ÄúDeep Think‚Äù capabilities, became generally available on **June 17, 2025**. A Flash‚ÄëLite variant optimized for speed and cost-efficiency was also introduced. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai))\n",
       "\n",
       "- **Nano Banana (Gemini 2.5 Flash Image)**  \n",
       "  Released on **August 26, 2025**, this image generation and editing model went viral for its photorealistic ‚Äú3D figurine‚Äù outputs. It supports subject consistency, multi-image fusion, and SynthID watermarking, and quickly amassed over 10 million new users and 200 million image edits. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))\n",
       "\n",
       "- **Google Gemini Diffusion**  \n",
       "  An experimental model that applies diffusion techniques to text generation, enabling simultaneous token generation and mid-process error correction. It achieves speeds up to 1,479 tokens per second‚Äîfar exceeding Gemini 2.5 Flash (~400 tps) and GPT‚Äë4o (~150 tps). ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai))\n",
       "\n",
       "- **Alibaba Qwen3 Series**  \n",
       "  Released in April 2025, Qwen3 includes open-source models ranging from 0.6B to 32B parameters, plus Mixture-of-Experts variants. They support ‚Äúthinking‚Äù and ‚Äúnon-thinking‚Äù modes and perform strongly on coding, math, and instruction-following tasks. ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai))\n",
       "\n",
       "- **Anthropic Claude Haiku 4.5**  \n",
       "  A compact model delivering flagship-level reasoning and coding performance at 4‚Äì5√ó the speed and roughly one-third the cost of larger models. It features a 200K token context window and agentic capabilities like ‚Äúusing computers‚Äù to automate tasks. ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Emerging Applications & Ecosystem Integration\n",
       "\n",
       "- **TIME AI Agent**  \n",
       "  Launched **today**, this platform integrates language understanding, voice synthesis, translation, and search to deliver interactive, personalized journalism. Developed with Scale AI, it emphasizes editorial accuracy and transparency. ([time.com](https://time.com/7332572/the-story-behind-the-time-ai-agent/?utm_source=openai))\n",
       "\n",
       "- **Microsoft MAI‚ÄëImage‚Äë1**  \n",
       "  Released **5 days ago**, this proprietary text-to-image generator offers fast, photorealistic image creation via Bing Image Creator and Copilot Audio Expressions. It complements OpenAI models and reflects Microsoft‚Äôs push for in-house AI capabilities. ([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/microsoft-copilot/microsoft-launches-mai-image-1?utm_source=openai))\n",
       "\n",
       "- **Google DS STAR**  \n",
       "  A multi-agent framework unveiled recently that translates ambiguous business problems into executable Python code, handling mixed-format data (CSV, JSON, Markdown, unstructured text) without human intervention. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **Meta Vibes Expansion**  \n",
       "  Meta‚Äôs AI-generated short video platform, Vibes, has expanded into Europe, offering TikTok-like experiences where every video is AI-generated. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **Google Maps + Gemini Integration**  \n",
       "  Gemini AI is being integrated into Google Maps as a voice assistant to simplify navigation via natural language. The rollout is global and ongoing. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **HeyGen AI Video Translator**  \n",
       "  This tool delivers hyper-realistic localization by matching tone, expressions, and lip movements in translated videos. Available via web, iOS, and API with free trial credits. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **ClickUp 4.0**  \n",
       "  Released recently, this update introduces AI agents and a redesigned UI, integrating task management, collaboration, messaging, scheduling, and enterprise search into a unified platform. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **OpenAI Sora for Android**  \n",
       "  Launched on **November 6, 2025**, Sora is a video app that achieved nearly 470,000 downloads on its first day‚Äîsurpassing its iOS debut by 327%. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Market Trends & Strategic Insights\n",
       "\n",
       "- **Generative AI Market Growth**  \n",
       "  The generative AI market experienced triple-digit growth across hardware, foundation models, and development platforms in 2024. Cloud providers are investing heavily in data centers, with over **US$400 billion** expected in AI-related spending in 2025. ([businesswire.com](https://www.businesswire.com/news/home/20250825682581/en/Generative-AI-Market-Report-2025-GenAI-Market-Experienced-Triple-digit-growth-Rates-in-All-Three-Major-Segments-Spanning-GenAI-Hardware-Foundation-Models-and-Development-Platforms---ResearchAndMarkets.com?utm_source=openai))\n",
       "\n",
       "- **Enterprise Adoption & Scaling**  \n",
       "  According to the 2025 McKinsey Global Survey, about one-third of organizations are scaling AI programs, while 39% are experimenting with agentic AI systems. High performers are more likely to redesign workflows, define human validation processes, and allocate over 20% of digital budgets to AI. ([mckinsey.com](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai?utm_source=openai))\n",
       "\n",
       "- **Responsible AI Practices**  \n",
       "  UC Berkeley‚Äôs Responsible Use of Generative AI playbook outlines 10 actionable strategies‚Äîfive for business leaders and five for product managers‚Äîto ensure ethical and responsible GenAI deployment. ([weforum.org](https://www.weforum.org/stories/2025/06/responsible-generative-ai-product-development-use/?utm_source=openai))\n",
       "\n",
       "- **Productivity Impact Study**  \n",
       "  A randomized controlled trial found that experienced open-source developers using early-2025 AI tools took **19% longer** to complete tasks, suggesting that AI may introduce friction in complex workflows. ([metr.org](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary\n",
       "\n",
       "The generative AI landscape in late 2025 is defined by:\n",
       "\n",
       "- **Advanced multimodal models** like GPT‚Äë5, Gemini 2.5, and Claude Haiku 4.5 pushing the boundaries of reasoning, context, and efficiency.\n",
       "- **Rapid integration** of AI into everyday tools‚Äîfrom journalism (TIME AI Agent) to navigation (Google Maps) and productivity platforms (ClickUp).\n",
       "- **Market momentum**, with massive investments and enterprise adoption accelerating the shift from experimentation to scaling.\n",
       "- **Ethical and practical challenges**, including responsible deployment and real-world productivity impacts.\n",
       "\n",
       "Let me know if you'd like a deeper dive into any specific model, application, or trend!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9eedf50-48f8-4092-bb20-c150f3848671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created: vs_69126a90413881919bb1ac715bab912f\n",
      "File uploaded: file-NNFBvy1y5VYAuKHpcsu8Yi\n",
      "File attached to vector store: file-NNFBvy1y5VYAuKHpcsu8Yi\n",
      "\n",
      "Top retrieved chunks:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tiy_vector_store = client.vector_stores.create(\n",
    "    name=\"tiy_vector_store\"\n",
    ")\n",
    "tiy_vector_store_id = tiy_vector_store.id\n",
    "print(\"Vector store created:\", tiy_vector_store_id)\n",
    "\n",
    "with open(\"343Lab10NewsClip.txt\", \"rb\") as f:\n",
    "    uploaded_file = client.files.create(\n",
    "        file=f,\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "print(\"File uploaded:\", uploaded_file.id)\n",
    "\n",
    "\n",
    "attach_result = client.vector_stores.files.create(\n",
    "    vector_store_id=tiy_vector_store_id,\n",
    "    file_id=uploaded_file.id,\n",
    ")\n",
    "print(\"File attached to vector store:\", attach_result.id)\n",
    "\n",
    "\n",
    "test_query = \"Summarize the main ideas from my notes.\"\n",
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=tiy_vector_store_id,\n",
    "    query=test_query,\n",
    ")\n",
    "\n",
    "print(\"\\nTop retrieved chunks:\")\n",
    "for item in search_results.data[:3]:\n",
    "    print(\"-\" * 40)\n",
    "    print(item.content[0].text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a structured summary of the topic **El Paso, Texas, and changes following the immigration crackdown**, divided into two sections as requested:\n",
       "\n",
       "From my file(s)  \n",
       "----------------  \n",
       "*(No relevant content was found in the uploaded file(s) regarding El Paso, Texas, and changes following an immigration crackdown. Please let me know if you'd like me to search again or if there‚Äôs a specific document I should focus on.)*\n",
       "\n",
       "From the web  \n",
       "------------\n",
       "\n",
       "**1. Expansion of Military Enforcement**  \n",
       "- In May 2025, the U.S. Department of Defense designated a second military zone along the U.S.‚ÄìMexico border, extending into Texas and connecting with Fort Bliss in El Paso. This allows military personnel to detain migrants who cross illegally until they are transferred to DHS, bypassing the Posse Comitatus Act.([apnews.com](https://apnews.com/article/d7d15f23bd755b95cd90cbb9a89df6fa?utm_source=openai))  \n",
       "- Under Operation Lone Star, Texas has deployed National Guard troops to El Paso. In early 2025, an agreement with the Trump administration authorized Guard members to make immigration arrests under CBP supervision.([elpasomatters.org](https://elpasomatters.org/2025/02/03/texas-national-guard-immigration-arrests-under-trump-abbott-agreement/?utm_source=openai))\n",
       "\n",
       "**2. Detention Infrastructure Expansion**  \n",
       "- In August 2025, ICE opened the ‚ÄúLone Star Lockup,‚Äù a mega detention facility at Fort Bliss in El Paso. Initially holding 1,000 people, it is planned to expand to 5,000 beds with a $1 billion investment. The facility has drawn criticism over transparency, access to legal counsel, and human rights concerns.([time.com](https://time.com/7310657/ice-immigration-detention-texas-lone-star-lockup/?utm_source=openai))\n",
       "\n",
       "**3. Humanitarian and Community Impact**  \n",
       "- Faith leaders in El Paso, including Catholic Bishop Mark Seitz, have raised alarms over the crackdown‚Äôs impact on migrants and humanitarian organizations. Policies extending enforcement into ‚Äúsensitive locations‚Äù like churches and schools have instilled fear, disrupted legal aid services, and led some migrants to return to dangerous conditions in their home countries.([kwbu.org](https://www.kwbu.org/news-from-across-texas/2025-06-27/fear-and-faith-el-paso-church-leaders-sound-the-alarm-amid-ice-crackdown?utm_source=openai))  \n",
       "- Legal aid organizations such as Estrella del Paso have lost significant federal funding‚Äîabout $5 million‚Äîand had to furlough staff. Emergency grants have provided temporary relief.([kwbu.org](https://www.kwbu.org/news-from-across-texas/2025-06-27/fear-and-faith-el-paso-church-leaders-sound-the-alarm-amid-ice-crackdown?utm_source=openai))\n",
       "\n",
       "**4. Legal and Political Developments**  \n",
       "- The Texas Supreme Court ruled in May 2025 that Attorney General Ken Paxton may resume his investigation into Annunciation House, a Catholic migrant shelter in El Paso, potentially revoking its charter.([houstonchronicle.com](https://www.houstonchronicle.com/politics/texas/article/annunciation-house-ken-paxton-20353327.php?utm_source=openai))  \n",
       "- In federal court, the Fifth Circuit upheld an injunction blocking Texas‚Äôs S.B. 4, a state law allowing local officials to arrest and deport migrants, reaffirming federal authority over immigration.([en.wikipedia.org](https://en.wikipedia.org/wiki/United_States_v._Texas_%282024%29?utm_source=openai))\n",
       "\n",
       "**5. Rising Migrant Deaths and Shifting Routes**  \n",
       "- Since El Paso joined Operation Lone Star in late 2022, the number of migrant deaths in the region has surged. From January 2023 to August 2024, 299 human remains were found in the El Paso sector‚Äîmore than double the 122 recorded in the prior 20 months.([click2houston.com](https://www.click2houston.com/news/texas/2025/06/16/after-el-paso-joined-abbotts-border-crackdown-the-number-of-dead-migrants-in-the-new-mexico-desert-surged/?utm_source=openai))  \n",
       "- The militarized enforcement has pushed migrants into more dangerous routes, particularly through the New Mexico desert, where deaths have increased significantly.([texastribune.org](https://www.texastribune.org/2025/06/16/texas-operation-lone-star-border-el-paso-deaths-migrants-new-mexico/?utm_source=openai))\n",
       "\n",
       "**Summary**  \n",
       "El Paso has become a focal point of intensified immigration enforcement, marked by military zone designations, expanded detention capacity, and state-federal cooperation in arrests. These measures have strained humanitarian services, provoked legal battles, and contributed to a tragic rise in migrant deaths. Community leaders and faith-based organizations continue to resist and adapt, even as legal and political pressures mount.\n",
       "\n",
       "Let me know if you'd like a deeper dive into any of these areas or additional context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "query = (\n",
    "    \"Using the uploaded news article as the primary source, and also checking the latest web information, \"\n",
    "    \"give me a short, structured summary of the topic (El Paso Texas and change following immigration crackdown). Clearly separate 'From my file' vs 'From the web'.\"\n",
    ")\n",
    "\n",
    "combined_response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=query,\n",
    "    temperature=0,\n",
    "    instructions=(\n",
    "        \"First look up relevant passages from the attached vector store. \"\n",
    "        \"Then augment with web_search to bring in current/public info. \"\n",
    "        \"Present the answer in two sections: 'From my file(s)' and 'From the web'.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [tiy_vector_store_id],\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Markdown(combined_response.output_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc541c21-863e-41bb-a62f-80fa7ab7ebb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
